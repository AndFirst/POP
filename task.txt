Optymalizacja hiperparametrów algorytmu xgboost za pomocą algorytmów heurystycznych

Algorytm xgboost jest uważany za jedną z najlepszych metod klasyfikacji. Niestety jego stosowanie jest utrudnione ze względu na bardzo dużą liczbę hiperparametrów takich jak np. liczba produkowanych drzew decyzyjnych, ich głębokość, krok uczenia, wielkość podzbiorów losowanych przy kolejnym kroku etc. Wymienione atrybuty często optymalizowane są ręcznie w ograniczony sposób. Zadanie to można jednak robić w mądrzejszy sposób wykorzystując algorytmy heurystyczne. W ramach tematu tego projektu należy przetestować różne algorytmy heurystyczne/populacyjne w kontekście problemu strojenia hiperparametrów algorytmu xgboost. Jakość działania algorytmów należy przetestować na podstawie dowolnego (nietrywialnego) zbioru. Np: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction. 
