{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'results.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in data.items():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    algorithm, metric, dataset = key.split('-')\n",
    "    for i in range(10):\n",
    "        history = value[i][1][1]\n",
    "        plt.plot(history, alpha=0.5, label=f'Przebieg {i + 1}')\n",
    "        \n",
    "    mean_history = np.mean([np.array(value[i][1][1]) for i in range(10)], axis=0)\n",
    "    plt.plot(mean_history, linewidth=4, color='black', label='Średnia')\n",
    "    plt.title(f'Przebieg optymalizacji hiperparametrów xgboost przy użyciu algorytmu {algorithm}, metryki {metric}, na zbiorze danych {dataset}.', fontsize='x-large', weight='bold')\n",
    "    plt.legend(loc='lower right', fontsize='x-large')\n",
    "    plt.ylabel(\"Ocena\", fontsize='large')\n",
    "    plt.xlabel(\"Runda\", fontsize='large')\n",
    "    plt.savefig(f'plots/history/{key}.png' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in data.items():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    algorithm, metric, dataset = key.split('-')\n",
    "    \n",
    "    best_point_val_list = [value[i][1][0] for i in range(10)]\n",
    "    best_point_test_list = [value[i][1][2] for i in range(10)]\n",
    "\n",
    "    plt.boxplot([best_point_val_list, best_point_test_list], labels=['Zbiór walidacyjny', 'Zbiór testowy'])\n",
    "    \n",
    "    val_df = pd.DataFrame(best_point_val_list)\n",
    "    test_df = pd.DataFrame(best_point_test_list)\n",
    "    \n",
    "    val_stats = val_df.describe()\n",
    "    test_stats = test_df.describe()\n",
    "    \n",
    "    stats_text_left = '\\n'.join([f'{stat[1]}: {value:.4f}' for stat, value in val_stats.transpose().stack().items() if stat[1] != 'count'])\n",
    "    stats_text_right = '\\n'.join([f'{stat[1]}: {value:.4f}' for stat, value in test_stats.transpose().stack().items() if stat[1] != 'count'])\n",
    "\n",
    "    plt.title(f'Oceny najlepszych parametrów uzyskanych przy użyciu algorytmu {algorithm}, metryki {metric}, na zbiorze danych {dataset}', fontsize='x-large', weight='bold')\n",
    "    plt.legend(loc='lower right', fontsize='large')\n",
    "\n",
    "    plt.text(0.05, 0.5, stats_text_left, transform=plt.gca().transAxes, fontsize=12, verticalalignment='center')\n",
    "    plt.text(0.85, 0.5, stats_text_right, transform=plt.gca().transAxes, fontsize=12, verticalalignment='center')\n",
    "    \n",
    "    plt.xticks(fontsize='large')\n",
    "    plt.yticks(fontsize='large')\n",
    "    plt.ylabel(\"Ocena\", fontsize='large')\n",
    "    plt.savefig(f'plots/best_results/{key}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
